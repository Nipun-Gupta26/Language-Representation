{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from scipy.spatial import procrustes\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English FastText embedding\n",
    "english_ft = fasttext.load_model('../fasttext/cc.en.300.bin')\n",
    "english_embeddings = np.array([english_ft.get_word_vector(word) for word in english_ft.words])\n",
    "english_word_to_index = {word: index for index, word in enumerate(english_ft.words)}\n",
    "\n",
    "# Load Hindi FastText embeddings\n",
    "hindi_ft = fasttext.load_model('../fasttext/cc.hi.300.bin')\n",
    "hindi_embeddings = np.array([hindi_ft.get_word_vector(word) for word in hindi_ft.words])\n",
    "hindi_word_to_index = {word: index for index, word in enumerate(hindi_ft.words)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000, 1876665)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_embeddings), len(hindi_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MUSE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cross_alignment_data/hi-en.0-5000.txt', encoding='utf-8') as f:\n",
    "    train_muse = [line.strip().split('\\t') for line in f]\n",
    "\n",
    "with open('../cross_alignment_data/hi-en.5000-6500.txt', encoding='utf-8') as f:\n",
    "    test_muse = [line.strip().split('\\t') for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_muse = [(en, hi) for hi, en in train_muse]\n",
    "test_muse = [(en, hi) for hi, en in test_muse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8001, 1963)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_muse), len(test_muse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self Generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../cross_alignment_data/word_pairs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "train_data = data[:2200]\n",
    "test_data = data[2200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 287)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (muse test set) between English and Hindi embeddings before alignment: 0.011090410609272662\n"
     ]
    }
   ],
   "source": [
    "cosine = 0\n",
    "total = 0\n",
    "for pair in test_muse:\n",
    "    if pair[0] in english_word_to_index and pair[1] in hindi_word_to_index:\n",
    "        english_embedding = english_embeddings[english_word_to_index[pair[0]]].reshape(1, -1)\n",
    "        hindi_embedding = hindi_embeddings[hindi_word_to_index[pair[1]]].reshape(1, -1)\n",
    "        cosine += cosine_similarity(english_embedding, hindi_embedding)[0][0]\n",
    "        total += 1\n",
    "\n",
    "cosine = cosine / total\n",
    "print(f\"Cosine similarity (muse test set) between English and Hindi embeddings before alignment: {cosine}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (self test set) between English and Hindi embeddings before alignment: 0.012925518298541884\n"
     ]
    }
   ],
   "source": [
    "cosine = 0\n",
    "total = 0\n",
    "for pair in test_data:\n",
    "    if pair[0] in english_word_to_index and pair[1] in hindi_word_to_index:\n",
    "        english_embedding = english_embeddings[english_word_to_index[pair[0]]].reshape(1, -1)\n",
    "        hindi_embedding = hindi_embeddings[hindi_word_to_index[pair[1]]].reshape(1, -1)\n",
    "        cosine += cosine_similarity(english_embedding, hindi_embedding)[0][0]\n",
    "        total += 1\n",
    "\n",
    "cosine = cosine / total\n",
    "print(f\"Cosine similarity (self test set) between English and Hindi embeddings before alignment: {cosine}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word pairs: 7910\n"
     ]
    }
   ],
   "source": [
    "def align_embeddings(source_embeddings, target_embeddings, source_word_to_index, target_word_to_index, word_pairs):\n",
    "    source_aligned = []\n",
    "    target_aligned = []\n",
    "    total = 0\n",
    "    for pair in word_pairs:\n",
    "        if pair[1] in source_word_to_index and pair[0] in target_word_to_index:\n",
    "            source_aligned.append(source_embeddings[source_word_to_index[pair[1]]])\n",
    "            target_aligned.append(target_embeddings[target_word_to_index[pair[0]]])\n",
    "            total += 1\n",
    "\n",
    "    source_aligned = np.array(source_aligned)\n",
    "    target_aligned = np.array(target_aligned)\n",
    "    print(f\"Number of word pairs: {total}\")\n",
    "\n",
    "    rotation, _ = orthogonal_procrustes(source_aligned, target_aligned)\n",
    "\n",
    "    return rotation\n",
    "\n",
    "rotation_matrix = align_embeddings(hindi_embeddings, english_embeddings, hindi_word_to_index, english_word_to_index, train_muse)\n",
    "    \n",
    "aligned_hindi_embeddings = np.dot(hindi_embeddings, rotation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word pairs: 1810\n"
     ]
    }
   ],
   "source": [
    "rotation_matrix_self = align_embeddings(hindi_embeddings, english_embeddings, hindi_word_to_index, english_word_to_index, train_data)\n",
    "aligned_hindi_embeddings_self = np.dot(hindi_embeddings, rotation_matrix_self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results with alignment using MUSE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (muse test set) between English and Hindi embeddings after procrustes alignment: 0.38694756478754216\n"
     ]
    }
   ],
   "source": [
    "cosine = 0\n",
    "total = 0\n",
    "for pair in test_muse:\n",
    "    if pair[0] in english_word_to_index and pair[1] in hindi_word_to_index:\n",
    "        english_embedding = english_embeddings[english_word_to_index[pair[0]]].reshape(1, -1)\n",
    "        hindi_embedding = aligned_hindi_embeddings[hindi_word_to_index[pair[1]]].reshape(1, -1)\n",
    "        cosine += cosine_similarity(english_embedding, hindi_embedding)[0][0]\n",
    "        total += 1\n",
    "\n",
    "cosine = cosine / total\n",
    "print(f\"Cosine similarity (muse test set) between English and Hindi embeddings after procrustes alignment: {cosine}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (self test set) between English and Hindi embeddings after procrustes alignment: 0.4614004105005575\n"
     ]
    }
   ],
   "source": [
    "cosine = 0\n",
    "total = 0\n",
    "for pair in test_data:\n",
    "    if pair[0] in english_word_to_index and pair[1] in hindi_word_to_index:\n",
    "        english_embedding = english_embeddings[english_word_to_index[pair[0]]].reshape(1, -1)\n",
    "        hindi_embedding = aligned_hindi_embeddings[hindi_word_to_index[pair[1]]].reshape(1, -1)\n",
    "        cosine += cosine_similarity(english_embedding, hindi_embedding)[0][0]\n",
    "        total += 1\n",
    "\n",
    "cosine = cosine / total\n",
    "print(f\"Cosine similarity (self test set) between English and Hindi embeddings after procrustes alignment: {cosine}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results with alignment using self generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (muse test set) between English and Hindi embeddings after procrustes alignment: 0.33125310747870435\n"
     ]
    }
   ],
   "source": [
    "cosine = 0\n",
    "total = 0\n",
    "for pair in test_muse:\n",
    "    if pair[0] in english_word_to_index and pair[1] in hindi_word_to_index:\n",
    "        english_embedding = english_embeddings[english_word_to_index[pair[0]]].reshape(1, -1)\n",
    "        hindi_embedding = aligned_hindi_embeddings_self[hindi_word_to_index[pair[1]]].reshape(1, -1)\n",
    "        cosine += cosine_similarity(english_embedding, hindi_embedding)[0][0]\n",
    "        total += 1\n",
    "\n",
    "cosine = cosine / total\n",
    "print(f\"Cosine similarity (muse test set) between English and Hindi embeddings after procrustes alignment: {cosine}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (self test set) between English and Hindi embeddings after procrustes alignment: 0.455227070334165\n"
     ]
    }
   ],
   "source": [
    "cosine = 0\n",
    "total = 0\n",
    "for pair in test_data:\n",
    "    if pair[0] in english_word_to_index and pair[1] in hindi_word_to_index:\n",
    "        english_embedding = english_embeddings[english_word_to_index[pair[0]]].reshape(1, -1)\n",
    "        hindi_embedding = aligned_hindi_embeddings_self[hindi_word_to_index[pair[1]]].reshape(1, -1)\n",
    "        cosine += cosine_similarity(english_embedding, hindi_embedding)[0][0]\n",
    "        total += 1\n",
    "\n",
    "cosine = cosine / total\n",
    "print(f\"Cosine similarity (self test set) between English and Hindi embeddings after procrustes alignment: {cosine}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
